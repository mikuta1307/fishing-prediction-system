#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ã‚¢ã‚¸é‡£æœäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«

æœ¬ç‰§æµ·é‡£ã‚Šæ–½è¨­ã®ã‚¢ã‚¸é‡£æœã‚’äºˆæ¸¬ã™ã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«
- Random Forestå›å¸°ãƒ¢ãƒ‡ãƒ«
- XGBoostå›å¸°ãƒ¢ãƒ‡ãƒ«
- ãƒ¢ãƒ‡ãƒ«è¨“ç·´ãƒ»äºˆæ¸¬ãƒ»è©•ä¾¡ãƒ»ä¿å­˜æ©Ÿèƒ½
- è‡ªå‹•ãƒ¢ãƒ‡ãƒ«ç®¡ç†æ©Ÿèƒ½ï¼ˆæœ€æ–°2ã¤ä¿æŒï¼‰
"""

import os
import glob
import numpy as np
import pandas as pd
import joblib
from datetime import datetime
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split, TimeSeriesSplit, cross_val_score
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')

import xgboost as xgb

class AjiPredictor:
    """ã‚¢ã‚¸é‡£æœäºˆæ¸¬ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model_type='xgboost'):
        """
        åˆæœŸåŒ–
        
        Args:
            model_type (str): ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ— ('random_forest' or 'xgboost')
        """
        self.model_type = model_type
        self.model = None
        self.feature_columns = None
        self.is_trained = False
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        self.model_dir = "models"
        if not os.path.exists(self.model_dir):
            os.makedirs(self.model_dir)
            print(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ: {self.model_dir}")
        
        # è¨“ç·´å±¥æ­´
        self.training_history = {}
        
        # ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self._initialize_model()
    
    def _initialize_model(self):
        """ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–"""
        if self.model_type == 'random_forest':
            self.model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                min_samples_split=5,
                min_samples_leaf=2,
                random_state=42,
                n_jobs=-1
            )
            print(f"ğŸŒ² Random Forestãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
            
        elif self.model_type == 'xgboost':
            self.model = xgb.XGBRegressor(
                n_estimators=100,
                max_depth=6,
                learning_rate=0.1,
                subsample=0.8,
                colsample_bytree=0.8,
                random_state=42,
                n_jobs=-1
            )
            print(f"ğŸš€ XGBoostãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–å®Œäº†")
            
        else:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«: {self.model_type}")
    
    def fit(self, X, y, validation_split=0.2):
        """
        ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
        
        Args:
            X (pd.DataFrame): ç‰¹å¾´é‡
            y (pd.Series): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
            validation_split (float): æ¤œè¨¼ç”¨ãƒ‡ãƒ¼ã‚¿ã®å‰²åˆ
        
        Returns:
            dict: è¨“ç·´çµæœ
        """
        print(f"ğŸ¯ {self.model_type}ãƒ¢ãƒ‡ãƒ«è¨“ç·´é–‹å§‹")
        print("=" * 50)
        
        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
        print(f"ğŸ“Š è¨“ç·´ãƒ‡ãƒ¼ã‚¿: X{X.shape}, y{y.shape}")
        print(f"ğŸ“ˆ é‡£æœæ•°çµ±è¨ˆ: å¹³å‡{y.mean():.1f}, ç¯„å›²{y.min()}-{y.max()}")
        
        # ç‰¹å¾´é‡åã‚’ä¿å­˜
        self.feature_columns = X.columns.tolist()
        
        # æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆéå»â†’æœªæ¥ã®é †åºã‚’ä¿æŒï¼‰
        train_size = int(len(X) * (1 - validation_split))
        X_train = X.iloc[:train_size]
        X_val = X.iloc[train_size:]
        y_train = y.iloc[:train_size]
        y_val = y.iloc[train_size:]
        
        print(f"ğŸ“… æ™‚ç³»åˆ—åˆ†å‰²: è¨“ç·´{len(X_train)}è¡Œ, æ¤œè¨¼{len(X_val)}è¡Œ")
        
        # ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        print(f"ğŸ”§ {self.model_type}ãƒ¢ãƒ‡ãƒ«è¨“ç·´ä¸­...")
        start_time = datetime.now()
        
        self.model.fit(X_train, y_train)
        
        training_time = (datetime.now() - start_time).total_seconds()
        print(f"âœ… è¨“ç·´å®Œäº†ï¼ˆ{training_time:.2f}ç§’ï¼‰")
        
        # äºˆæ¸¬å®Ÿè¡Œ
        y_train_pred = self.model.predict(X_train)
        y_val_pred = self.model.predict(X_val)
        
        # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
        train_metrics = self._calculate_metrics(y_train, y_train_pred, "è¨“ç·´")
        val_metrics = self._calculate_metrics(y_val, y_val_pred, "æ¤œè¨¼")
        
        # è¨“ç·´å±¥æ­´ä¿å­˜
        self.training_history = {
            'model_type': self.model_type,
            'training_time': training_time,
            'train_size': len(X_train),
            'val_size': len(X_val),
            'train_metrics': train_metrics,
            'val_metrics': val_metrics,
            'feature_columns': self.feature_columns,
            'trained_at': datetime.now().isoformat()
        }
        
        self.is_trained = True
        
        # çµæœè¡¨ç¤º
        self._print_training_results()
        
        # ç‰¹å¾´é‡é‡è¦åº¦è¡¨ç¤º
        self._print_feature_importance()
        
        return self.training_history
    
    def _calculate_metrics(self, y_true, y_pred, dataset_name):
        """è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—"""
        mae = mean_absolute_error(y_true, y_pred)
        rmse = np.sqrt(mean_squared_error(y_true, y_pred))
        r2 = r2_score(y_true, y_pred)
        
        metrics = {
            'mae': mae,
            'rmse': rmse,
            'r2': r2,
            'mean_actual': float(y_true.mean()),
            'mean_predicted': float(y_pred.mean())
        }
        
        return metrics
    
    def _print_training_results(self):
        """è¨“ç·´çµæœã®è¡¨ç¤º"""
        print(f"\nğŸ“Š {self.model_type}ãƒ¢ãƒ‡ãƒ«è©•ä¾¡çµæœ")
        print("=" * 50)
        
        train_metrics = self.training_history['train_metrics']
        val_metrics = self.training_history['val_metrics']
        
        print(f"ğŸ¯ è¨“ç·´ãƒ‡ãƒ¼ã‚¿è©•ä¾¡:")
        print(f"  MAE:  {train_metrics['mae']:.1f}åŒ¹")
        print(f"  RMSE: {train_metrics['rmse']:.1f}åŒ¹")
        print(f"  RÂ²:   {train_metrics['r2']:.3f}")
        
        print(f"\nğŸ” æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿è©•ä¾¡:")
        print(f"  MAE:  {val_metrics['mae']:.1f}åŒ¹")
        print(f"  RMSE: {val_metrics['rmse']:.1f}åŒ¹")
        print(f"  RÂ²:   {val_metrics['r2']:.3f}")
        
        # éå­¦ç¿’ãƒã‚§ãƒƒã‚¯
        mae_diff = val_metrics['mae'] - train_metrics['mae']
        r2_diff = train_metrics['r2'] - val_metrics['r2']
        
        print(f"\nğŸ” éå­¦ç¿’ãƒã‚§ãƒƒã‚¯:")
        print(f"  MAEå·®åˆ†: {mae_diff:+.1f}åŒ¹ ({'âš ï¸éå­¦ç¿’' if mae_diff > 50 else 'âœ…è‰¯å¥½'})")
        print(f"  RÂ²å·®åˆ†:  {r2_diff:+.3f} ({'âš ï¸éå­¦ç¿’' if r2_diff > 0.1 else 'âœ…è‰¯å¥½'})")
    
    def _print_feature_importance(self):
        """ç‰¹å¾´é‡é‡è¦åº¦ã®è¡¨ç¤º"""
        if not hasattr(self.model, 'feature_importances_'):
            return
        
        importance = self.model.feature_importances_
        feature_importance = pd.DataFrame({
            'ç‰¹å¾´é‡': self.feature_columns,
            'é‡è¦åº¦': importance
        }).sort_values('é‡è¦åº¦', ascending=False)
        
        print(f"\nğŸ” ç‰¹å¾´é‡é‡è¦åº¦ (ä¸Šä½5ä½):")
        for i, (_, row) in enumerate(feature_importance.head(5).iterrows(), 1):
            print(f"  {i}. {row['ç‰¹å¾´é‡']}: {row['é‡è¦åº¦']:.3f}")
    
    def predict(self, X):
        """
        äºˆæ¸¬å®Ÿè¡Œ
        
        Args:
            X (pd.DataFrame or np.array): ç‰¹å¾´é‡
        
        Returns:
            np.array: äºˆæ¸¬å€¤
        """
        if not self.is_trained:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚å…ˆã«fit()ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        
        # DataFrameã®å ´åˆã¯ç‰¹å¾´é‡é †åºã‚’ãƒã‚§ãƒƒã‚¯
        if isinstance(X, pd.DataFrame):
            if list(X.columns) != self.feature_columns:
                print("âš ï¸ ç‰¹å¾´é‡ã®é †åºã‚’èª¿æ•´ã—ã¦ã„ã¾ã™")
                X = X[self.feature_columns]
        
        predictions = self.model.predict(X)
        
        # è² ã®å€¤ã‚’0ã«ã‚¯ãƒªãƒƒãƒ—ï¼ˆé‡£æœæ•°ã¯éè² ï¼‰
        predictions = np.maximum(predictions, 0)
        
        return predictions
    
    def predict_single(self, month, season, weather, temp, tide, visitors):
        """
        å˜ä¸€æ¡ä»¶ã§ã®äºˆæ¸¬ï¼ˆä¾¿åˆ©é–¢æ•°ï¼‰- å‰Šæ¸›ç‰ˆ6ç‰¹å¾´é‡å¯¾å¿œ
        
        Args:
            month (int): æœˆ (1-12)
            season (int): å­£ç¯€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ (0=æ˜¥, 1=å¤, 2=ç§‹, 3=å†¬)
            weather (int): å¤©æ°—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ (0=æ™´ã‚Œ, 1=æ›‡ã‚Š, 2=é›¨, 3=é›ª)
            temp (float): æ°´æ¸© (â„ƒ)
            tide (int): æ½®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ (0=å¤§æ½®, 1=ä¸­æ½®, 2=å°æ½®, 3=é•·æ½®, 4=è‹¥æ½®)
            visitors (int): æ¥å ´è€…æ•° (äºº)
        
        Returns:
            float: äºˆæ¸¬ã‚¢ã‚¸é‡£æœæ•°
        """
        # ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ä½œæˆï¼ˆ6å€‹ã®ç‰¹å¾´é‡ï¼‰
        features = np.array([[month, season, weather, temp, tide, visitors]])
        
        # äºˆæ¸¬å®Ÿè¡Œ
        prediction = self.predict(features)[0]
        
        return prediction
    
    def cross_validate(self, X, y, cv_folds=5):
        """
        äº¤å·®æ¤œè¨¼ã®å®Ÿè¡Œ
        
        Args:
            X (pd.DataFrame): ç‰¹å¾´é‡
            y (pd.Series): ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°
            cv_folds (int): äº¤å·®æ¤œè¨¼ã®åˆ†å‰²æ•°
        
        Returns:
            dict: äº¤å·®æ¤œè¨¼çµæœ
        """
        print(f"ğŸ”„ {cv_folds}-foldäº¤å·®æ¤œè¨¼å®Ÿè¡Œä¸­...")
        
        # æ™‚ç³»åˆ—äº¤å·®æ¤œè¨¼
        tscv = TimeSeriesSplit(n_splits=cv_folds)
        
        # MAEã‚¹ã‚³ã‚¢
        mae_scores = -cross_val_score(
            self.model, X, y, 
            cv=tscv, 
            scoring='neg_mean_absolute_error',
            n_jobs=-1
        )
        
        # RÂ²ã‚¹ã‚³ã‚¢
        r2_scores = cross_val_score(
            self.model, X, y,
            cv=tscv,
            scoring='r2',
            n_jobs=-1
        )
        
        cv_results = {
            'mae_mean': mae_scores.mean(),
            'mae_std': mae_scores.std(),
            'r2_mean': r2_scores.mean(),
            'r2_std': r2_scores.std(),
            'mae_scores': mae_scores.tolist(),
            'r2_scores': r2_scores.tolist()
        }
        
        print(f"âœ… äº¤å·®æ¤œè¨¼å®Œäº†:")
        print(f"  MAE: {cv_results['mae_mean']:.1f} Â± {cv_results['mae_std']:.1f}åŒ¹")
        print(f"  RÂ²:  {cv_results['r2_mean']:.3f} Â± {cv_results['r2_std']:.3f}")
        
        return cv_results
    
    def cleanup_old_models(self, keep_count=2):
        """
        å¤ã„ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã€æœ€æ–°ã®keep_countå€‹ã®ã¿ä¿æŒ
        
        Args:
            keep_count (int): ä¿æŒã™ã‚‹ãƒ¢ãƒ‡ãƒ«æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2ï¼‰
        
        Returns:
            dict: å‰Šé™¤ãƒ»ä¿æŒçµæœ
        """
        # ãƒ¢ãƒ‡ãƒ«ç¨®åˆ¥åˆ¥ã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³
        pattern = os.path.join(self.model_dir, f"aji_{self.model_type}_*.pkl")
        model_files = glob.glob(pattern)
        
        if len(model_files) <= keep_count:
            return {
                'deleted_files': [],
                'kept_files': model_files,
                'message': f"ä¿æŒå¯¾è±¡{keep_count}å€‹ä»¥ä¸‹ã®ãŸã‚å‰Šé™¤ä¸è¦"
            }
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥æ™‚ã‚’æŠ½å‡ºã—ã¦ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        def extract_datetime(filepath):
            filename = os.path.basename(filepath)
            # aji_random_forest_20250730_163124.pkl â†’ 20250730_163124
            try:
                datetime_part = filename.split('_')[-2] + '_' + filename.split('_')[-1].replace('.pkl', '')
                return datetime.strptime(datetime_part, '%Y%m%d_%H%M%S')
            except:
                # æ—¥æ™‚æŠ½å‡ºå¤±æ•—æ™‚ã¯ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆæ™‚åˆ»ã‚’ä½¿ç”¨
                return datetime.fromtimestamp(os.path.getctime(filepath))
        
        # æ—¥æ™‚é †ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        model_files.sort(key=extract_datetime, reverse=True)
        
        # ä¿æŒãƒ»å‰Šé™¤ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ±ºå®š
        files_to_keep = model_files[:keep_count]
        files_to_delete = model_files[keep_count:]
        
        deleted_files = []
        for file_path in files_to_delete:
            try:
                os.remove(file_path)
                deleted_files.append(os.path.basename(file_path))
                print(f"ğŸ—‘ï¸  å‰Šé™¤: {os.path.basename(file_path)}")
            except Exception as e:
                print(f"âš ï¸  å‰Šé™¤å¤±æ•—: {os.path.basename(file_path)} - {e}")
        
        return {
            'deleted_files': deleted_files,
            'kept_files': [os.path.basename(f) for f in files_to_keep],
            'message': f"{len(deleted_files)}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã€{len(files_to_keep)}å€‹ã‚’ä¿æŒ"
        }
    
    def save_model(self, filename=None):
        """
        ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ï¼ˆè‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä»˜ãï¼‰
        
        Args:
            filename (str): ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆçœç•¥æ™‚ã¯è‡ªå‹•ç”Ÿæˆï¼‰
        
        Returns:
            str: ä¿å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        if not self.is_trained:
            raise ValueError("è¨“ç·´ã•ã‚Œã¦ã„ãªã„ãƒ¢ãƒ‡ãƒ«ã¯ä¿å­˜ã§ãã¾ã›ã‚“")
        
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"aji_{self.model_type}_{timestamp}.pkl"
        
        filepath = os.path.join(self.model_dir, filename)
        
        # ãƒ¢ãƒ‡ãƒ«ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        model_data = {
            'model': self.model,
            'model_type': self.model_type,
            'feature_columns': self.feature_columns,
            'training_history': self.training_history,
            'is_trained': self.is_trained
        }
        
        joblib.dump(model_data, filepath)
        print(f"ğŸ’¾ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {filepath}")
        
        # å¤ã„ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        print("ğŸ§¹ å¤ã„ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
        cleanup_result = self.cleanup_old_models(keep_count=2)
        
        if cleanup_result['deleted_files']:
            print(f"âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†: {cleanup_result['message']}")
            print(f"   ğŸ“ ä¿æŒãƒ•ã‚¡ã‚¤ãƒ«: {', '.join(cleanup_result['kept_files'])}")
        else:
            print(f"â„¹ï¸  {cleanup_result['message']}")
        
        return filepath
    
    def list_models(self):
        """
        ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¸€è¦§è¡¨ç¤º
        
        Returns:
            list: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã®ãƒªã‚¹ãƒˆ
        """
        pattern = os.path.join(self.model_dir, "aji_*.pkl")
        model_files = glob.glob(pattern)
        
        model_info = []
        for filepath in model_files:
            filename = os.path.basename(filepath)
            file_size = os.path.getsize(filepath)
            modified_time = datetime.fromtimestamp(os.path.getmtime(filepath))
            
            # ãƒ¢ãƒ‡ãƒ«ç¨®åˆ¥ã‚’æ¨å®š
            if 'random_forest' in filename:
                model_type = 'Random Forest'
            elif 'xgboost' in filename:
                model_type = 'XGBoost'
            else:
                model_type = 'Unknown'
            
            model_info.append({
                'filename': filename,
                'model_type': model_type,
                'size_mb': file_size / 1024 / 1024,
                'modified': modified_time,
                'filepath': filepath
            })
        
        # æ›´æ–°æ—¥æ™‚é †ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        model_info.sort(key=lambda x: x['modified'], reverse=True)
        
        print(f"\nğŸ“ ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§ ({len(model_info)}å€‹)")
        print("=" * 80)
        for i, info in enumerate(model_info, 1):
            print(f"{i:2d}. {info['filename']}")
            print(f"    ğŸ“Š ç¨®åˆ¥: {info['model_type']}")
            print(f"    ğŸ“‚ ã‚µã‚¤ã‚º: {info['size_mb']:.1f}MB")
            print(f"    ğŸ“… æ›´æ–°: {info['modified'].strftime('%Y/%m/%d %H:%M:%S')}")
            print()
        
        return model_info
    
    def load_model(self, filepath):
        """
        ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        
        Args:
            filepath (str): ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        
        Returns:
            bool: èª­ã¿è¾¼ã¿æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            if not os.path.exists(filepath):
                print(f"âŒ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
                return False
            
            model_data = joblib.load(filepath)
            
            self.model = model_data['model']
            self.model_type = model_data['model_type']
            self.feature_columns = model_data['feature_columns']
            self.training_history = model_data['training_history']
            self.is_trained = model_data['is_trained']
            
            print(f"âœ… ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿å®Œäº†: {filepath}")
            print(f"ğŸ“Š ãƒ¢ãƒ‡ãƒ«: {self.model_type}")
            print(f"ğŸ¯ ç‰¹å¾´é‡æ•°: {len(self.feature_columns)}")
            
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def get_model_info(self):
        """ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã®å–å¾—"""
        if not self.is_trained:
            return {"status": "æœªè¨“ç·´"}
        
        return {
            "model_type": self.model_type,
            "is_trained": self.is_trained,
            "feature_columns": self.feature_columns,
            "training_history": self.training_history
        }


def create_sample_prediction():
    """ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬ã®å®Ÿè¡Œä¾‹ï¼ˆå‰Šæ¸›ç‰ˆ6ç‰¹å¾´é‡å¯¾å¿œï¼‰"""
    print("ğŸ¯ ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬å®Ÿè¡Œ")
    print("=" * 40)
    
    # ã‚µãƒ³ãƒ—ãƒ«æ¡ä»¶ï¼ˆ8æœˆ1æ—¥åœŸæ›œæ—¥ã€å¤ã€æ™´ã‚Œã€æ°´æ¸©27â„ƒã€å¤§æ½®ã€æ¥å ´è€…200äººï¼‰
    sample_conditions = {
        'month': 8,          # 8æœˆ
        'season': 1,         # å¤
        'weather': 0,        # æ™´ã‚Œ
        'temp': 27.0,        # æ°´æ¸©27â„ƒ
        'tide': 0,           # å¤§æ½®
        'visitors': 200      # æ¥å ´è€…200äºº
    }
    
    print("ğŸ“… äºˆæ¸¬æ¡ä»¶:")
    print(f"  æ—¥ä»˜: 8æœˆï¼ˆå¤ãƒ»æ™´ã‚Œï¼‰")
    print(f"  æ°´æ¸©: {sample_conditions['temp']}â„ƒ")
    print(f"  æ½®: å¤§æ½®, æ¥å ´è€…: {sample_conditions['visitors']}äºº")
    
    return sample_conditions


def select_model_type():
    """ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—é¸æŠ"""
    print("ğŸ¤– ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„:")
    print("  1. Random Forestï¼ˆå®‰å®šæ€§é‡è¦–ãƒ»è§£é‡ˆã—ã‚„ã™ã„ï¼‰")
    print("  2. XGBoostï¼ˆé«˜ç²¾åº¦ãƒ»ç«¶æŠ€å‘ã‘ï¼‰")
    
    while True:
        try:
            choice = input("\né¸æŠ (1 or 2): ").strip()
            if choice == "1":
                return "random_forest"
            elif choice == "2":
                return "xgboost"
            else:
                print("âŒ 1 ã¾ãŸã¯ 2 ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸ")
            exit(0)
        except Exception:
            print("âŒ ç„¡åŠ¹ãªå…¥åŠ›ã§ã™ã€‚1 ã¾ãŸã¯ 2 ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")


def main():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸŸ ã‚¢ã‚¸é‡£æœäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«å­¦ç¿’")
    print("=" * 60)
    
    try:
        # ãƒ¢ãƒ‡ãƒ«é¸æŠ
        model_type = select_model_type()
        model_name = "Random Forest" if model_type == "random_forest" else "XGBoost"
        
        print(f"\nâœ… {model_name}ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ")
        print("=" * 60)
        
        # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        from data_loader import load_all_data
        from feature_engineering import AjiFishingFeatureEngineer
        
        print("ğŸ“Š ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
        fishing_df, comment_df = load_all_data()
        
        if fishing_df is None:
            print("âŒ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å¤±æ•—")
            return
        
        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
        print("ğŸ”§ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Ÿè¡Œä¸­...")
        feature_eng = AjiFishingFeatureEngineer()
        X, y = feature_eng.create_features(fishing_df)
        
        if X is None or y is None:
            print("âŒ ç‰¹å¾´é‡ä½œæˆå¤±æ•—")
            return
        
        # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã§å­¦ç¿’
        print(f"\n{'ğŸŒ²' if model_type == 'random_forest' else 'ğŸš€'} {model_name}ãƒ¢ãƒ‡ãƒ«å­¦ç¿’é–‹å§‹")
        print("=" * 50)
        
        predictor = AjiPredictor(model_type=model_type)
        results = predictor.fit(X, y)
        
        # äº¤å·®æ¤œè¨¼
        print(f"\nğŸ”„ {model_name}ãƒ¢ãƒ‡ãƒ«äº¤å·®æ¤œè¨¼ä¸­...")
        cv_results = predictor.cross_validate(X, y, cv_folds=3)
        
        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜ï¼ˆè‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä»˜ãï¼‰
        print(f"\nğŸ’¾ {model_name}ãƒ¢ãƒ‡ãƒ«ä¿å­˜ä¸­...")
        model_path = predictor.save_model()
        
        # ä¿å­˜æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§è¡¨ç¤º
        predictor.list_models()
        
        # ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬
        sample_conditions = create_sample_prediction()
        prediction = predictor.predict_single(**sample_conditions)
        print(f"ğŸ¯ {model_name}äºˆæ¸¬ã‚¢ã‚¸é‡£æœ: {prediction:.0f}åŒ¹")
        
        print(f"\nâœ… {model_name}ãƒ¢ãƒ‡ãƒ«å­¦ç¿’å®Œäº†!")
        print(f"ğŸ’¾ ä¿å­˜å ´æ‰€: {model_path}")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()